{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the dataset "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pathlib\nimport tensorflow as tf\ndata_dir = pathlib.Path('../input/pcbexperiment/dataset/tobeaugmented')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#count total number of images in the directory\nimage_count = len(list(data_dir.glob('*/*.jpg')))\nprint(image_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\ndefected_count = next(os.walk('../input/pcbexperiment/dataset/tobeaugmented/defected'))[2] \ndc=len(defected_count)\nprint(\"Images for defected PCB : \",dc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nlist = os.listdir('../input/pcbexperiment/dataset/tobeaugmented/non-defect') # dir is your directory path\nnc = len(list)\nprint(\"Image count for non-defect PCB :\",nc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Is the dataset imbalanced?\nwe can check the imbalanceness of the dataset for differet classes by plotting the bar graph using matplotlib library using this code"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nx = [\"Defected PCB\",\"non-defect PCB\"]\ny = [dc,nc]\nplt.barh(x, y)\nfor index, value in enumerate(y):\n    plt.text(value, index, str(value))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here,we see that the number of images for defected PCB/1 is very less compared to the non-defect PCB/0. Hence the dataset is imbalanced due to which the dominating class cause unfair results."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nonlyfiles = next(os.walk('../input/pcbexperiment/dataset/tobeaugmented/non-defect'))[2] #dir is your directory path as string\nprint(len(onlyfiles))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport os\nimport PIL\nimport PIL.Image\nimport tensorflow as tf\nimport tensorflow_datasets as tfds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\n#...\ndefected_path='../input/pcbexperiment/dataset/tobeaugmented/defected/20200707_085703.jpg'\nimg = Image.open(defected_path)\nPIL.Image.open(defected_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\n#...\nnondefectpath='../input/pcbexperiment/dataset/tobeaugmented/non-defect/20200630_114408(1).jpg'\nimg = Image.open(nondefectpath)\nPIL.Image.open(nondefectpath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nimg_height = 180\nimg_width = 180","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = train_ds.class_names\nprint(class_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image_batch, labels_batch in train_ds:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Standardize the data\nThe RGB channel values are in the [0, 255] range. This is not ideal for a neural network; in general you should seek to make your input values small. Here, we will standardize values to be in the [0, 1] by using a Rescaling layer."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import layers\n\nnormalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = 2\n\nmodel = tf.keras.Sequential([\n  layers.experimental.preprocessing.Rescaling(1./255),\n  layers.Conv2D(32, 3, activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n  optimizer='Nadam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=3\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, accuracy = model.evaluate(val_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}